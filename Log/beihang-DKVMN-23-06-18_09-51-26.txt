Namespace(batch_size=64, checkpoint_dir=None, cuda=True, data_augment=False, dataset='beihang', device='cuda', dropout=0.2, edge_types=2, embed_dim=128, graph_type='Dense', hidden_dim=50, lr=0.001, max_seq_len=200, memory_size=20, model='DKVMN', n_epochs=20, output_dim=100, pretrain='load', pretrain_embed_file='Dataset/beihang/embed_pretrain.npz', q_num=332, qs_matrix=tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [1., 0., 0.,  ..., 0., 0., 0.],
        [1., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.]]), s_num=15, shuffle=True)-----------------------------------------------------------Delta Time : 0.0Best val_auc in epoch -1: train_auc:  0.739182557918687  train_loss:  0.5745114088058472  train_acc:  0.6969394114179389  val_auc:  0.7376819588261475  val_loss:  0.5787193179130554  val_acc:  0.693396566259941  Best val_auc in epoch -1: train_auc:  0.739182557918687  train_loss:  0.5745114088058472  train_acc:  0.6969394114179389  val_auc:  0.7376819588261475  val_loss:  0.5787193179130554  val_acc:  0.693396566259941  Best val_auc in epoch -1: train_auc:  0.739182557918687  train_loss:  0.5745114088058472  train_acc:  0.6969394114179389  val_auc:  0.7376819588261475  val_loss:  0.5787193179130554  val_acc:  0.693396566259941  Best val_auc in epoch -1: train_auc:  0.739182557918687  train_loss:  0.5745114088058472  train_acc:  0.6969394114179389  val_auc:  0.7376819588261475  val_loss:  0.5787193179130554  val_acc:  0.693396566259941  Best val_auc in epoch -1: train_auc:  0.739182557918687  train_loss:  0.5745114088058472  train_acc:  0.6969394114179389  val_auc:  0.7376819588261475  val_loss:  0.5787193179130554  val_acc:  0.693396566259941  Best val_auc in epoch -1: train_auc:  0.739182557918687  train_loss:  0.5745114088058472  train_acc:  0.6969394114179389  val_auc:  0.7376819588261475  val_loss:  0.5787193179130554  val_acc:  0.693396566259941  -----------------------------------------------------------{'train_auc': [0.5475571866927224, 0.6459077970516203, 0.6911954126692484, 0.7149782351652763, 0.7248180658831662, 0.7294663299421147, 0.7312539035005285, 0.7332077265558544, 0.7335777025858555, 0.7343991122130797, 0.7353593294948523, 0.7363274228138355, 0.7365416900045443, 0.7371650670205447, 0.737826727919418, 0.7380238614872747, 0.7380494466491067, 0.7384343657144148, 0.7393734655464832, 0.739182557918687], 'train_loss': [0.67323744, 0.63586193, 0.6102406, 0.5935349, 0.5863668, 0.5827783, 0.58092904, 0.57963437, 0.5791672, 0.57849145, 0.5777526, 0.57711136, 0.57707787, 0.57658464, 0.5762045, 0.57558465, 0.57565224, 0.5757075, 0.57513314, 0.5745114], 'train_acc': [0.5863996473801427, 0.6473758276139904, 0.6745940431499948, 0.6841495953485981, 0.6891049529535637, 0.6910395804904725, 0.6914442075807059, 0.6928298797206488, 0.6929056200481292, 0.6933548024956899, 0.6944268933123249, 0.6939659101538279, 0.6942821777057615, 0.6953927723137964, 0.6952966169515086, 0.6963533805603536, 0.6959868828785153, 0.6958909397515026, 0.6966969747674898, 0.6969394114179389], 'val_auc': [0.6128045590590094, 0.6741495215598693, 0.7047546542531092, 0.7219269355248147, 0.727370434981584, 0.7308390045046863, 0.7316547051841118, 0.7328780239437998, 0.7332784381961048, 0.7332556935734544, 0.734297448319779, 0.7346033000000229, 0.7359338837930889, 0.7360124713240175, 0.7358775172521739, 0.7361490644495101, 0.7362018344202134, 0.7373517849586892, 0.7364223117328583, 0.7376819588261475], 'val_loss': [0.6526371, 0.62444544, 0.6027731, 0.5911091, 0.5865346, 0.5843488, 0.58325016, 0.58238304, 0.58151627, 0.5814934, 0.580576, 0.5812293, 0.5804747, 0.5803745, 0.5798713, 0.5796657, 0.5796531, 0.57943785, 0.5795289, 0.5787193], 'val_acc': [0.6289515538417316, 0.6617810704208853, 0.6760555640538135, 0.6827494439950572, 0.6866723178845217, 0.6887246129263117, 0.6905795591061519, 0.6904623584795085, 0.6918540431849978, 0.6918701549976294, 0.6925334209844227, 0.6926129827188499, 0.6926880273525209, 0.6932302711225778, 0.6926653238763442, 0.6938309444477063, 0.6933894604648583, 0.6926335177410742, 0.6931900449602398, 0.693396566259941]}