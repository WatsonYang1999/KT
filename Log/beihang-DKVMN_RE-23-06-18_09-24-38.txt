Namespace(batch_size=64, checkpoint_dir=None, cuda=True, data_augment=False, dataset='beihang', device='cuda', dropout=0.2, edge_types=2, embed_dim=128, graph_type='Dense', hidden_dim=50, lr=0.001, max_seq_len=200, memory_size=20, model='DKVMN_RE', n_epochs=20, output_dim=100, pretrain='load', pretrain_embed_file='Dataset/beihang/embed_pretrain.npz', q_num=332, qs_matrix=tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [1., 0., 0.,  ..., 0., 0., 0.],
        [1., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.]]), s_num=15, shuffle=True)-----------------------------------------------------------Delta Time : 0.0Best val_auc in epoch -1: train_auc:  0.7421305531717955  train_loss:  0.5739258527755737  train_acc:  0.6998493381353228  val_auc:  0.7405593177725329  val_loss:  0.5715803503990173  val_acc:  0.7023829953987479  Best val_auc in epoch -1: train_auc:  0.7421305531717955  train_loss:  0.5739258527755737  train_acc:  0.6998493381353228  val_auc:  0.7405593177725329  val_loss:  0.5715803503990173  val_acc:  0.7023829953987479  Best val_auc in epoch -1: train_auc:  0.7421305531717955  train_loss:  0.5739258527755737  train_acc:  0.6998493381353228  val_auc:  0.7405593177725329  val_loss:  0.5715803503990173  val_acc:  0.7023829953987479  Best val_auc in epoch -1: train_auc:  0.7421305531717955  train_loss:  0.5739258527755737  train_acc:  0.6998493381353228  val_auc:  0.7405593177725329  val_loss:  0.5715803503990173  val_acc:  0.7023829953987479  Best val_auc in epoch -1: train_auc:  0.7421305531717955  train_loss:  0.5739258527755737  train_acc:  0.6998493381353228  val_auc:  0.7405593177725329  val_loss:  0.5715803503990173  val_acc:  0.7023829953987479  Best val_auc in epoch -1: train_auc:  0.7421305531717955  train_loss:  0.5739258527755737  train_acc:  0.6998493381353228  val_auc:  0.7405593177725329  val_loss:  0.5715803503990173  val_acc:  0.7023829953987479  -----------------------------------------------------------{'train_auc': [0.6123496031026596, 0.7048701886906575, 0.7226818046147174, 0.7276769228618332, 0.7298094189166214, 0.731570025206197, 0.7322119508961651, 0.7330245094868216, 0.7346905398344596, 0.7350713385497124, 0.735914748233109, 0.7365785420675345, 0.7374775749751591, 0.7377452950736356, 0.7380843070781078, 0.7398657440774585, 0.7398837128998408, 0.7405442821659177, 0.74100465399704, 0.7421305531717955], 'train_loss': [0.6547852, 0.6041547, 0.5887686, 0.58469903, 0.5829588, 0.58169734, 0.58134264, 0.5803964, 0.5794102, 0.57940286, 0.57835877, 0.5778285, 0.5778202, 0.5773455, 0.5761261, 0.57540596, 0.5756255, 0.5748323, 0.5747457, 0.57392585], 'train_acc': [0.6245231591609832, 0.6777674254738699, 0.6847628193479164, 0.6888578377223927, 0.6901671374345313, 0.6907051585721712, 0.6908761759234008, 0.6918383995699282, 0.6927651588972835, 0.6928479892840242, 0.6946637395848605, 0.6948245704903375, 0.6954905802143451, 0.6963217896016948, 0.6969637885748081, 0.6978185300825723, 0.6973616323019016, 0.6984922292931763, 0.6991866047672964, 0.6998493381353228], 'val_auc': [0.6898230310938608, 0.7187442930626255, 0.7243923351457433, 0.7268425284140674, 0.7291569886414908, 0.7302691674793695, 0.7319608295518112, 0.7315420659121006, 0.7325829121440559, 0.7338063602915503, 0.7348748258208107, 0.7352188125219092, 0.7361649039019956, 0.7365672765429572, 0.7376170189686391, 0.7387950566873304, 0.7385988314575203, 0.7400167638692715, 0.7401594580440769, 0.7405593177725329], 'val_loss': [0.61457145, 0.5874514, 0.5830519, 0.58167255, 0.57997745, 0.5792278, 0.57835716, 0.5783411, 0.57775337, 0.5770869, 0.57628804, 0.57624644, 0.57516205, 0.5745756, 0.5734543, 0.5735397, 0.57289326, 0.5719567, 0.5722374, 0.57158035], 'val_acc': [0.6755359746063627, 0.6876499640035132, 0.6901084778982843, 0.6924792959800554, 0.6942848884780096, 0.694445725742644, 0.6965297267415739, 0.6950842107972809, 0.6967333417529193, 0.697062317354457, 0.698706971129153, 0.6989171451776877, 0.6987165763745653, 0.7012142664828434, 0.7000041835916916, 0.7020277855151914, 0.7012441819865867, 0.7030563719168089, 0.7021433134373372, 0.7023829953987479]}