Namespace(batch_size=64, checkpoint_dir=None, cuda=True, data_augment=False, dataset='beihang', device='cuda', dropout=0.2, edge_types=2, embed_dim=128, graph_type='Dense', hidden_dim=50, lr=0.001, max_seq_len=200, memory_size=20, model='DKVMN_RE', n_epochs=20, output_dim=100, pretrain='load', pretrain_embed_file='Dataset/beihang/embed_pretrain.npz', q_num=332, qs_matrix=tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [1., 0., 0.,  ..., 0., 0., 0.],
        [1., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.]]), s_num=15, shuffle=True)-----------------------------------------------------------Delta Time : 0.0Best val_auc in epoch -1: train_auc:  0.7426088399168974  train_loss:  0.5715304613113403  train_acc:  0.6996302320254049  val_auc:  0.7446706971854669  val_loss:  0.5757265090942383  val_acc:  0.697378404996201  Best val_auc in epoch -1: train_auc:  0.7426088399168974  train_loss:  0.5715304613113403  train_acc:  0.6996302320254049  val_auc:  0.7446706971854669  val_loss:  0.5757265090942383  val_acc:  0.697378404996201  Best val_auc in epoch -1: train_auc:  0.7426088399168974  train_loss:  0.5715304613113403  train_acc:  0.6996302320254049  val_auc:  0.7446706971854669  val_loss:  0.5757265090942383  val_acc:  0.697378404996201  Best val_auc in epoch -1: train_auc:  0.7426088399168974  train_loss:  0.5715304613113403  train_acc:  0.6996302320254049  val_auc:  0.7446706971854669  val_loss:  0.5757265090942383  val_acc:  0.697378404996201  Best val_auc in epoch -1: train_auc:  0.7426088399168974  train_loss:  0.5715304613113403  train_acc:  0.6996302320254049  val_auc:  0.7446706971854669  val_loss:  0.5757265090942383  val_acc:  0.697378404996201  Best val_auc in epoch -1: train_auc:  0.7426088399168974  train_loss:  0.5715304613113403  train_acc:  0.6996302320254049  val_auc:  0.7446706971854669  val_loss:  0.5757265090942383  val_acc:  0.697378404996201  -----------------------------------------------------------{'train_auc': [0.5965563181900431, 0.6985614207093986, 0.7177320772204487, 0.7244890474483017, 0.7287212503755365, 0.7300344718904435, 0.731751458115257, 0.7331109028739614, 0.7339120858189767, 0.7354690886730083, 0.7365689344818018, 0.7360294750203292, 0.7373237456849053, 0.7366334031956169, 0.7383246445925816, 0.7391154334723217, 0.7388038971735187, 0.7403258922696547, 0.7420872169247124, 0.7426088399168974], 'train_loss': [0.6567052, 0.60560095, 0.5900989, 0.58479583, 0.5823421, 0.5810378, 0.57974875, 0.5785772, 0.5782195, 0.5771211, 0.5763059, 0.5766794, 0.5753923, 0.5754691, 0.5748218, 0.5745391, 0.5745446, 0.5734448, 0.5723509, 0.57153046], 'train_acc': [0.6179990531656939, 0.6779452421220908, 0.6852888649543748, 0.688597651683865, 0.6903525959019364, 0.6921122119012886, 0.6924233423443069, 0.6932666219563342, 0.6936605309787425, 0.6955813591837673, 0.6946101381249175, 0.6950024071768167, 0.6965062948391532, 0.6964228306612313, 0.6969194611861556, 0.6971382833397156, 0.6969861126338313, 0.6979843510407366, 0.6987506559049836, 0.6996302320254049], 'val_auc': [0.6797640147452174, 0.7152783309870194, 0.726810063193815, 0.7282430230750887, 0.7313050769788733, 0.7337849510457689, 0.7354708409486423, 0.7367133594165587, 0.7358874197313053, 0.7376889982686412, 0.7387256953701682, 0.7376076063047863, 0.7391610532727491, 0.7404209725026876, 0.7402065840281621, 0.7399603801952171, 0.7418771045707904, 0.7412039057306609, 0.7425643272418977, 0.7446706971854669], 'val_loss': [0.62731636, 0.598603, 0.58929026, 0.58794415, 0.585846, 0.58399713, 0.5826804, 0.58185285, 0.5825857, 0.58129185, 0.580002, 0.5805416, 0.57978976, 0.5793436, 0.57906526, 0.578859, 0.5774454, 0.5774337, 0.57681, 0.5757265], 'val_acc': [0.6585732630011323, 0.6770087565270618, 0.6828110393576463, 0.6833137021519147, 0.6851275483116085, 0.6864998275487268, 0.6875026575763318, 0.6879597054700642, 0.6886481679783336, 0.6903102845214886, 0.6904835568034159, 0.6913662388758156, 0.6927039909322047, 0.6927346993047602, 0.6918173187400256, 0.6929144896159566, 0.6933992553179521, 0.6948322963093015, 0.6953774173496313, 0.697378404996201]}