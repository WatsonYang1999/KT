Namespace(batch_size=64, checkpoint_dir=None, cuda=True, data_augment=False, dataset='beihang', device='cuda', dropout=0.2, edge_types=2, embed_dim=128, graph_type='Dense', hidden_dim=50, lr=0.001, max_seq_len=200, memory_size=20, model='DKVMN_RE', n_epochs=20, output_dim=100, pretrain='load', pretrain_embed_file='Dataset/beihang/embed_pretrain.npz', q_num=332, qs_matrix=tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [1., 0., 0.,  ..., 0., 0., 0.],
        [1., 1., 0.,  ..., 0., 0., 0.],
        ...,
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.],
        [1., 0., 1.,  ..., 0., 0., 0.]]), s_num=15, shuffle=True)-----------------------------------------------------------Delta Time : 0.0Best val_auc in epoch -1: train_auc:  0.7471074069524607  train_loss:  0.5684890151023865  train_acc:  0.7031631466816476  val_auc:  0.7426447855283097  val_loss:  0.5774194002151489  val_acc:  0.6983380452411156  Best val_auc in epoch -1: train_auc:  0.7471074069524607  train_loss:  0.5684890151023865  train_acc:  0.7031631466816476  val_auc:  0.7426447855283097  val_loss:  0.5774194002151489  val_acc:  0.6983380452411156  Best val_auc in epoch -1: train_auc:  0.7471074069524607  train_loss:  0.5684890151023865  train_acc:  0.7031631466816476  val_auc:  0.7426447855283097  val_loss:  0.5774194002151489  val_acc:  0.6983380452411156  Best val_auc in epoch -1: train_auc:  0.7471074069524607  train_loss:  0.5684890151023865  train_acc:  0.7031631466816476  val_auc:  0.7426447855283097  val_loss:  0.5774194002151489  val_acc:  0.6983380452411156  Best val_auc in epoch -1: train_auc:  0.7471074069524607  train_loss:  0.5684890151023865  train_acc:  0.7031631466816476  val_auc:  0.7426447855283097  val_loss:  0.5774194002151489  val_acc:  0.6983380452411156  Best val_auc in epoch -1: train_auc:  0.7471074069524607  train_loss:  0.5684890151023865  train_acc:  0.7031631466816476  val_auc:  0.7426447855283097  val_loss:  0.5774194002151489  val_acc:  0.6983380452411156  -----------------------------------------------------------{'train_auc': [0.6019026524548498, 0.7038648344236222, 0.7249696881319257, 0.7314489024256703, 0.734558356380447, 0.7362581662575698, 0.7381125482739501, 0.7394771744241341, 0.7405166284712242, 0.7408937610022593, 0.7419614142686086, 0.7426353465552918, 0.7429282321724432, 0.7443173301852694, 0.7446811350831808, 0.745027453555767, 0.7448358766737946, 0.7466532486050826, 0.7472699860055735, 0.7471074069524607], 'train_loss': [0.6569134, 0.6057238, 0.585719, 0.5803457, 0.57789505, 0.5765467, 0.5754572, 0.5738863, 0.57356083, 0.5731741, 0.57190096, 0.5718177, 0.57117987, 0.5708908, 0.57021236, 0.5700201, 0.5702127, 0.5686813, 0.56856227, 0.568489], 'train_acc': [0.6206539850394617, 0.6759731697314244, 0.6893889053279241, 0.6922666618874863, 0.6934600932891712, 0.6941080826647215, 0.6955374263547854, 0.69613104040949, 0.6966871771457308, 0.6977777070286499, 0.6996483148284509, 0.6993679814379383, 0.7000876519750013, 0.7008797484286333, 0.7008621432153442, 0.7014066595362458, 0.7017014027114735, 0.7028958109128014, 0.7032723965555814, 0.7031631466816476], 'val_auc': [0.6867940490076178, 0.7170853914423722, 0.7255737945770763, 0.7303077815825454, 0.7320149788459425, 0.7340136364109544, 0.7348075708717561, 0.7361147133595539, 0.7365973989275346, 0.736184566005778, 0.7385997888119706, 0.7392140991385909, 0.7391656561067262, 0.7404603977030628, 0.7407622728614014, 0.7415948604665644, 0.742107582619537, 0.7423172781391894, 0.7410663382751455, 0.7426447855283097], 'val_loss': [0.626739, 0.5969356, 0.5895833, 0.586833, 0.58501846, 0.58414745, 0.58340484, 0.5821934, 0.5819148, 0.58144796, 0.5804003, 0.57982475, 0.5799693, 0.57923764, 0.57860166, 0.5783168, 0.5778888, 0.5777482, 0.57850945, 0.5774194], 'val_acc': [0.6564568703757117, 0.6806976339707616, 0.6868306473457421, 0.6875565967927751, 0.6903017678492989, 0.6927526562824579, 0.692937616401771, 0.6936777321380683, 0.6945385855871149, 0.694603926312112, 0.6959564134107474, 0.6967420869325653, 0.6963129194044002, 0.6979905335415708, 0.6982993815585357, 0.6975326250001997, 0.698555257190979, 0.6985268745541662, 0.6975071491698875, 0.6983380452411156]}